---
title: "Help yourself: Assignment 1"
author:
  - name: "[Michael McCarthy](https://github.com/mccarthy-m-g)"
    affiliation: "[PSYC 615 Lab](https://github.com/mccarthy-m-g/psyc-615-lab)"
    email: michael.mccarthy@ucalgary.ca
output:
  bookdown::html_document2:
    number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = "#>", collapse = TRUE)
```

## Prerequisites

To access the datasets, help pages, and functions that we will use in this *help yourself*, load the following packages:

```{r prerequisites}
here::i_am("labs/02_assumptions-ttests/help-yourself_assignment-1.Rmd")

library(here)
library(tidyverse)
library(ggpubr)
library(patchwork)
library(papaja)
library(psych)
library(broom)
library(car)
library(effectsize)
```

If you run this code and get the error message "there is no package called 'tidyverse'" (or a different package name), you will need to first install it, then run `library()` once again.

```{r, eval=FALSE}
install.packages("tidyverse")
library(tidyverse)
```

You only need to install a package once, but you need to reload it every time you start a new session.

If you need to be explicit about where a function (or dataset) comes from, you can use the special form `package::function()`. For example, `ggplot2::ggplot()` tells R explicitly that you are using the `ggplot()` function from the **ggplot2** package.

Telling R explicitly where a function comes from is called *namespacing*. The code below will always be explicit about where functions from loaded packages come from so that it is easier for you to help yourself when you want to learn more about a given function. However, you do not need to namespace functions in your code for assignments so long as you have the prerequisite packages loaded in your session.

## Creating data sets

There are many ways to create data sets in R. If you want to create a data set where the code is laid out like a spreadsheet you can use the `tribble()` function from the **tibble** package. This is useful if you want to create a small data set with values you input manually. To get help using this function you can run `?tibble::tribble` in the R console.

```{r tribble}
simpsons <- tibble::tribble(
  ~simpson, ~age,
  "homer",  36,
  "marge",  34,
  "bart",   10,
  "lisa",    8,
  "maggie",  1
)

simpsons
```

Alternatively, if you want to create a data set where each column is a vector of values you can use the `tibble()` function from the tibble package. To get help using this function you can run `?tibble::tibble` in the R console.

```{r tibble}
# Here we recreate the data set from the code chunk above using the tibble
# function
simpson_name <- c("homer", "marge", "bart", "lisa", "maggie")
simpson_age  <- c(36, 34, 10, 8, 1)

simpsons <- tibble::tibble(simpson = simpson_name, age = simpson_age)

simpsons
```

### Simulating data

Creating data sets using the `tibble()` function is useful when you want to simulate data instead of entering it manually. R comes built in with a number of functions to simulate data with different distributions. You can see them all by running `?distributions` in the console. The most useful distribution to simulate in this course will be the normal distribution, which can be simulated with the `rnorm()` function. To get help using this function you can run `?rnorm` in the R console.

```{r simulate}
normal_distribution <- rnorm(n = 10, mean = 30, sd = 5)

normal_distribution
```

All the simulation functions in R output vectors of values, which means you can use them with the `tibble()` function to create simulated data sets.

```{r simulated-dataset}
# Here we construct a data set using the simulated normal distribution from the
# code chunk above, with an additional column containing the participant ID for
# each simulated value
simulated_dataset <- tibble::tibble(id = 1:10, value = normal_distribution)

simulated_dataset
```

## Wrangling data

It is often the case that the data you work with needs wrangling to make it fit for use. This could mean cleaning the data, but it could also mean adding new columns, removing rows, calculating new values, or transforming old values. The **dplyr** package has you covered for all of these actions and more. There are six main functions that will cover the majority of your data wrangling needs:

### Selecting

The `select()` function (`?dplyr::select`) allows you to select (and optionally rename) columns in a data frame.

```{r select}
dplyr::select(.data = simpsons, age)
```

### Filtering

The `filter()` function (`?dplyr::filter`) is used to subset a data frame, retaining all rows that satisfy your conditions.

```{r filter}
dplyr::filter(.data = simpsons, simpson != "bart")
```

### Mutating

The `mutate()` function (`?dplyr::mutate`) adds new columns and preserves existing ones

```{r mutate}
dplyr::mutate(.data = simpsons, age_in_2021 = age + 34)
```

### Grouping and summarizing

The `group_by()` function (`?dplyr::group_by`) allows you to organize observations into groups and do data operations by group. The `ungroup()` function (`?dplyr::ungroup`) removes grouping.

The `summarize()` function (`?dplyr::summarize`) allows you to compute summary statistics on a data set either as a whole or by group by pairing it with the `group_by()` function.

```{r groupby-summarize}
# First we need a variable to group by. We can create it using the mutate
# function.
simpsons <- dplyr::mutate(
  .data = simpsons,
  sex = c("male", "female", "male", "female", "female"),
  .before = age
)

# Then we group the data by sex
simpsons_grouped <- dplyr::group_by(.data = simpsons, sex)

# And finally we calculate some summary statistics using our grouping variable
simpsons_grouped <- dplyr::summarize(
  .data = simpsons_grouped,
  group_size = dplyr::n(),
  mean_age = mean(age),
  sd_age = sd(age)
)

simpsons_grouped
```

The `summarize()` function can also be used independently to get summary statistics for the whole sample.

```{r summarize}
dplyr::summarize(
  .data = simpsons,
  total_age = sum(age),
  median_age = median(age),
  mean_age = mean(age),
  sd_age = sd(age)
)
```

### Arranging

The `arrange()` function (`?dplyr::arrange`) orders the rows of a data frame by the values of selected columns.

```{r arrange-ascending}
dplyr::arrange(.data = simpsons, age)
```

You can use the the `desc()` function (`?dplyr::desc`) to order the rows in descending order.

```{r arrange-descending}
dplyr::arrange(.data = simpsons, dplyr::desc(age))
```

## File paths

Before you can read data you need to tell R where the data file is located. There are several ways to do this, some of them better than others.

The easiest---but also easiest to break---way is to write a character string with a path to the file, relative to your current working directory. You can check your current working directory by running `getwd()` in the console. If you do this, you should see that your current working directory is the `psyc-615-lab` directory

```{r string-path}
string_path <- "data/help-yourself_01.csv"
string_path
```

A better way is to use the `file.path()` function (`?file.path`), which constructs the path to a file from components in a platform-independent way. This avoids file paths breaking between different operating systems, since Windows uses backslashes and OSX and Linux use forward slashes. 

```{r function-path}
function_path <- file.path("data", "help-yourself_01.csv")
function_path
```

The best way is to use the `here()` function (`?here::here`) from the **here** package. The `here()` function will always locate the files relative to your project root, in this case the `psyc-615-lab` directory. This is more consistent than locating files relative to your current working directory, and encourages the use of [project-oriented workflows](https://r4ds.had.co.nz/workflow-projects.html). You can use it as a drop-in replacement for `file.path()`.

```{r here-path}
here_path <- here::here("data", "help-yourself_01.csv")
here_path
```

You should read the here package vignettes to learn more about using `here()` in general (`vignette("here", package = "here")`) and in R Markdown documents such as this one (`vignette("rmarkdown", package = "here")`). After reading, if you scroll to line 15 of this document you will note that the `here::i_am()` function has already been set up for you. But you may need to set it up on your own at other points in this course.

## Reading data

There are a number of functions you can use to read different data files in R. For this course there are only two you need to worry about. To read CSV data files you can use the `read_csv()` (`?readr::read_csv`) function from the **readr** package.

```{r read-csv}
csv_data <- readr::read_csv(here::here("data", "help-yourself_01.csv"))
csv_data
```

To read SPSS `.sav` files you can use the `read_sav()` function (`?haven::read_sav`) from the **haven** package.

```{r read-spss}
sav_data <- haven::read_sav(here::here("data", "help-yourself_01.sav"))
sav_data
```

## Visualizing data

R is a powerhouse for visualizing data, and makes it easy to create publication ready plots and tables. 

### Creating plots

The plots you will make in this course will be simple, but if you enjoy data visualization then diving deeper into R's plotting capabilities is a great investment (check out the *#tidytuesday* tag on Twitter if you want a taste). Data visualization in R is typically done with the **ggplot2** package, which is based on a grammar of graphics that allow you to assemble plots step by step to your exact specifications. A companion to ggplot2 is the **ggpubr** package, which simplifies the creation of plots common to scientific publications in APA style.

#### Histograms and box plots

Histograms are useful for visualizing the distribution of observations for a given variable. The `gghistogram()` function (`?ggpubr::gghistogram`) can be used to create a histogram. You can change the number and width of bins with the optional `bins` and `binwidth` arguments.

```{r gghistogram}
ggpubr::gghistogram(data = csv_data, x = "anxiety")
```

An alternative way to visualize the distribution of observations for a given variable is with boxplots. This can be useful if you want to emphasize different percentiles of the data. The `ggboxplot()` function (`?ggpubr::ggboxplot`) can be used to create a box plot.

```{r ggboxplot}
ggpubr::ggboxplot(data = csv_data, y = "anxiety")
```

#### Q-Q plots

Quantile-Quantile plots are a useful visual aid for assessing whether the distribution of observations for a given variable approximate a theoretical distribution, such as a the normal distribution. The `ggqqplot()` function (`?ggpubr::ggqqplot`) can be used to create a Q-Q plot.

```{r ggqqplot}
ggpubr::ggqqplot(data = csv_data, x = "anxiety")
```

#### Bar plots and line plots

Bar plots can be used to visualize group differences. The `ggbarplot()` function (`?ggpubr::ggbarplot`) can be used to create a bar plot. The optional `add` argument can be used to add descriptive statistics to the bars, such as means and confidence intervals.

```{r ggbarplot}
ggpubr::ggbarplot(data = csv_data, x = "group", y = "anxiety", add = "mean_ci")
```

An alternative to bar plots are line plots. These can be useful when visualizing changes in repeated measures data.

```{r ggline}
ggpubr::ggline(data = csv_data, x = "group", y = "anxiety", add = "mean_ci")
```

### Composing plots

The plotting code above will serve your needs for most assignment questions in the course, but questions requiring APA style need a bit more formatting attention.

#### Labels

You may have noticed the axis labels in the plots above were all in lower case. Every plotting function in the ggpubr package has additional optional arguments---which you can see by going to the function's help page---that can be used to change plot labels. Here is an example with the `ggbarplot()` function; note the additional `xlab` and `ylab` arguments.

```{r labels}
ggpubr::ggbarplot(
  data = csv_data,
  x = "group",
  y = "anxiety",
  add = "mean_ci",
  xlab = "Group",
  ylab = "Anxiety"
)
```

#### Moving the legend

APA requires legends to be located within the plotting area, but ggplot2 places legends outside the plotting area by default. If your plot has a legend you can move it with the `apa_legend()` function. This is a custom function included in the PSYC 615 Lab repository, you can make it available by using the `source()` function. Options for the `position` argument are: "topleft", "topright", "topmiddle", "bottomleft", "bottomright", "bottommiddle", or "none".

```{r legends}
# The source function runs R script files so their contents can be made
# available to use in R Markdown documents such as this one
source(here::here("R", "apa_legend.R"))

# The fill argument groups the data, resulting in a legend. The palette
# argument is used to change the fill colour of the boxplots.
grouped_boxplot <- ggpubr::ggboxplot(
  data = csv_data,
  y = "anxiety",
  fill = "group",
  palette = "grey"
)

# Use ggplot2 syntax (the + sign) to move the legend
grouped_boxplot +
  apa_legend(position = "topleft")
```

#### Multiple plots as a single figure

The **patchwork** package makes it very easy to combine multiple plots into a single figure. Simply assign your plots to objects, then compose them using patchwork's syntax. Note: the patchwork library needs to be loaded for this to work; in this document it was loaded in the prerequisites section.

```{r patchwork}
# First create some plots
plot_a <- ggpubr::gghistogram(data = csv_data, x = "anxiety")
plot_b <- ggpubr::ggqqplot(data = csv_data, x = "anxiety")

# Then compose them together and add an annotation to distinguish them
plot_a + plot_b +
  patchwork::plot_annotation(tag_levels = "A")
```

#### Figure captions

APA style also requires figures to have captions. There are two ways to go about this in an R Markdown document. The first is to type the caption directly into the code chunk options of the chunk where your plot is output from, using the `fig.cap` chunk option (note: you need to look at the R Markdown file to see this, not the rendered document).

```{r caption-a, fig.cap="A short figure caption."}
ggpubr::ggboxplot(data = csv_data, y = "anxiety")
```

The second, and usually better, option is to place a reference to the caption in the code chunk options. You can see how this works below (note: you need to look at the R Markdown file to see this, not the rendered document).

<!-- ---------------------------------------------------------------------- -->
(ref:caption-b) When you have a long caption using the second option is better because it keeps your code chunk options short and clean.

```{r caption-b, fig.cap="(ref:caption-b)"}
ggpubr::ggboxplot(data = csv_data, y = "anxiety")
```

### Tables

R also has great packages for making tables. Unfortunately you will not get to play around with these in this course. Partly because you will only ever make very simple tables in this course, and partly because R's best table making packages do not support Microsoft Word documents at the moment.

The easiest way to output an APA style table in an R Markdown document is to use the `apa_table()` function (`?papaja::apa_table`) from the **papaja** package. This function takes a data frame and APA styles it when you knit your document, with an optional caption using the `caption` argument.

```{r papaja-table}
# If you run this code in the console the output will look like gibberish. You
# need to knit the document as a PDF or Word file to see the proper result.
apa_tab <- papaja::apa_table(simpsons, caption = "Table showing Simpsons ages")
```

However, you should note that the `apa_table()` function will not do all the APA styling work for you. Things such as capitalization, number of digits printed, and so forth must be either: (1) Handled beforehand in the data frame given to the `apa_table()` function; or (2) handled afterwords manually in Microsoft Word.

<!-- Note to future TAs or students who are fine messing with development versions of R packages: The gt package will have word support in the future. As of Aug 31, 2021, there is a PR in development on Word support https://github.com/rstudio/gt/pull/811. Once this is complete gt will likely be a better option than papaja for APA tables. Here is a blogpost showing how to make APA-like tables with gt https://www.anthonyschmidt.co/post/2020-06-03-making-apa-tables-with-gt/. This could be used currently by creating a gt table then saving it as a png; it's not as good as a native table in Word but it's workable and would allow students to use gt's capabilities for formatting nice tables. -->

## Including images

If you need to include any images in your R Markdown document you can use the `knitr::include_graphics()` function(`?knitr::include_graphics`)  from the **knitr** package. Note that you actually need to use the `knitr::` namespacing for this one. Images can also be given captions using the same method as with plots.

```{r images}
knitr::include_graphics(here::here("images", "outlier.png"))
```

## Descriptive statistics

### Mean and standard deviation

The `mean()` function (`?mean`) takes a vector of numbers as input and returns the mean as output. 

```{r mean}
zero_to_one_hundred <- 0:100

mean(zero_to_one_hundred)
```

The `sd()` function (`?sd`) works the same way as the `mean()` function, but returns the standard deviation as output.

```{r sd}
some_numbers <- c(1, 15, 98, 45, 37, 56)

sd(some_numbers)
```

### Skewness and kurtosis

The `skewness()` and `kurtosis()` functions (`?datawizard::skewness`) from the **datawizard** package can be used to calculate skewness and kurtosis. There are different algorithms for calculating skewness and kurtosis, these can be selected using the optional `type` argument (`type = 2` matches SPSS and SAS). 

```{r skewness-kurtosis}
datawizard::skewness(some_numbers)
datawizard::kurtosis(some_numbers)
```

### Calculate all descriptive statistics with a single function

You can also use the `describe()` function (`?psych::describe`) from the **psych** package to calculate all your descriptive statistics at once. The optional `type` argument selects which algorithm to calculate skewness and kurtosis with (`type = 2` matches SPSS and SAS). Note that the `describe()` function will calculate descriptive statistics for all columns in a data frame, even if that would not make sense for all columns. You can wrangle your data frame beforehand with the `select()` function from the dplyr package if you only want to see output for the relevant columns.

```{r describe}
psych::describe(csv_data, type = 2)
```

## Statistical assumptions

### Shapiro-Wilk test

The Shapiro-Wilk test of normality can be used to test whether the skewness of a variable is significantly different from a normal distribution. You can use the `shapiro.test()` function (`?shapiro.test`) to calculate the Shapiro-Wilk statistic ($W$) and the p-value for the test.

```{r shapiro-wilk}
shapiro.test(some_numbers)
```

The `shapiro.test()` function takes a numeric vector of values as its input, so you need to specify which column you would like to run the test for if your data is in a data frame. You can do this using either the `pull()` function (`?dplyr::pull`) from the dplyr package, or one of R's extract operators (`?Extract`).

```{r shapiro-wilk-df}
# The pull function lets you use a familiar syntax to other functions
anxiety_values_pull <- dplyr::pull(.data = csv_data, var = anxiety)

# R's extract operators have a unique syntax that is more concise. These are
# all interchangeable so you may see different ones used by different people.
anxiety_values_dollar <- csv_data$anxiety
anxiety_values_sqbr   <- csv_data[["anxiety"]]

# If you put any of the anxiety_values_ vectors in the shapiro.test() function
# below you will see that you get the same result for each
shapiro.test(anxiety_values_pull)
```

If you want easy programmatic access to the output of the `shapiro.test()` function you can use the `tidy()` function (`?broom::tidy`) from the **broom** package. This will tidy the output into a data frame, which you can then do other functions on. For instance, you might want to put the results in an APA table using the `apa_table()` function mentioned previously, or you might want to round the test statistic to two digits using the `round()` function. See the function help (`?broom::tidy.htest`) for details about what the value in each column means.

```{r shapiro-wilk-tidy}
shapiro_test_anxiety <- shapiro.test(anxiety_values_pull)

broom::tidy(shapiro_test_anxiety)
```

### Levene's test

Levene's test of homogeneity of variance can be used to test whether the variance of a variable is equal across groups. You can use the `leveneTest()` function (`?car::leveneTest`) from the **car** package to calculate the Levene's test statistic ($F$) and the p-value for the test. There are two ways to use this function, each giving the same result but with different syntax. Pick whichever you like.

The first option requires you to extract the variable and group columns you want to use to calculate Levene's test from your data frame.

```{r levene-extract}
# Here we extract the numeric vector for anxiety and the character vector for
# group from the `csv_data` data frame using the `$` extractor mentioned in the
# previous section.
car::leveneTest(y = csv_data$anxiety, group = csv_data$anxiety, center = mean)
```

The second option uses R's formula syntax, placing the variable column to the left of the tilde and the group column to the right, then specifying the data frame those columns belong to using the `data` argument.

```{r levenes-formula}
car::leveneTest(anxiety ~ group, center = mean, data = csv_data)
```

If you want easy programmatic access to the output of the `leveneTest()` function you can use the `tidy()` function (`?broom::tidy.leveneTest`) from the **broom** package here too (the `tidy()` function works with most statistical models in R). See the function help (`?broom::tidy.htest`) for details about what the value in each column means.

```{r levenes-tidy}
# Here we split this code up into multiple lines in order to follow the
# tidyverse style guide. The guide states that when a line of code exceeds 80
# characters it should be broken into multiple lines for readability.
levenes_test_anxiety <- car::leveneTest(
  anxiety ~ group,
  center = mean,
  data = csv_data
)

broom::tidy(levenes_test_anxiety)
```

## t-tests

All the different types of t-tests in R use the same `t.test()` function (`?t.test`), but each uses different optional arguments to determine which t-test is run. There are two ways to use this function for a given type of t-test, each way giving the same result but with different syntax (like with the `leveneTest()` function above).

### Single Sample t-test

The single sample t-test tests whether a group of values significantly differ from a specified value. It uses the optional `mu` argument to indicate the true value of the mean. You can either use this function with extracted values:

```{r single-sample-ttest-extract}
t.test(csv_data$anxiety, mu = 20)
```

Or with the formula syntax:

```{r single-sample-ttest-formula}
t.test(anxiety ~ 1, mu = 20, data = csv_data)
```

### Independent t-test

The independent t-test tests whether the values in two distinct unrelated groups significantly differ from each other.

You can either use this function with extracted values from each group:

```{r independent-ttest-extract}
# First you have to create separate data frames for each group. The filter
# function is the easiest way to do this.
spider_pic_group <- dplyr::filter(.data = csv_data, group == "Picture")
spider_real_group <- dplyr::filter(.data = csv_data, group == "Real Spider")

# Afterwords you can extract the same variable from each data frame to compare
# the two groups.
t.test(x = spider_pic_group$anxiety, y = spider_real_group$anxiety)
```

Or with the formula syntax, where the dependent variable goes to the left of the tilde and the independent variable goes to the right. (As you may have noticed by now R's formula syntax tends to result in cleaner, shorter code).

```{r independent-ttest-formula}
t.test(anxiety ~ group, data = csv_data)
```

### Dependent t-test

The dependent t-test tests whether the values within the same group (or a matched group) significantly differ across two contexts. It uses the optional `paired` argument to indicate that the values in your data are dependent on each other.

You can either use this function with extracted values from each group:

```{r dependent-ttest-extract}
# Here we can pretend participants first had their anxiety measured while
# looking at pictures of spiders, then afterwords had their anxiety measured
# while looking at real spiders.
t.test(
  x = spider_pic_group$anxiety,
  y = spider_real_group$anxiety,
  paired = TRUE
)
```

Or with the formula syntax, where the dependent variable goes to the left of the tilde and the independent variable goes to the right.

```{r dependent-ttest-formula}
t.test(anxiety ~ group, paired = TRUE, data = csv_data)
```

### Tidy t-tests

The output of the `t.test()` function can be tidied with the `tidy()` function  from the broom package. See the function help (`?broom::tidy.htest`) for details about what the value in each column means.

```{r ttest-tidy}
# This example uses the independent t-test code from the chunks above
ttest_fit_anxiety <- t.test(anxiety ~ group, data = csv_data)

broom::tidy(ttest_fit_anxiety)
```

### Cohen's d

The `cohens_d()` function (`?effectsize::cohens_d`) from the **effectsize** package can be used to calculate Cohen's d ($d$).

Just like with the `t-test()` function, you can either use this function with extracted values from each group.

```{r cohens-d-extract}
# This example calculates Cohen's d for the independent t-test in the code
# chunks above
effectsize::cohens_d(
  x = spider_pic_group$anxiety,
  y = spider_real_group$anxiety
)
```

Or with the formula syntax, where the dependent variable goes to the left of the tilde and the independent variable goes to the right.

```{r cohens-d-formula}
# This example calculates Cohen's d for the independent t-test in the code
# chunks above
effectsize::cohens_d(anxiety ~ group, data = csv_data)
```

The simplest approach is to choose whichever syntax you used with the t.test() function, since you can then drop the arguments you used there directly into `cohens_d()` without any changes.

## Learning more

add free resources

stats of doom
